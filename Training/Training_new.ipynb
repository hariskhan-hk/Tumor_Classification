{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da5bca5f",
   "metadata": {},
   "source": [
    "### I. Import Required Dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195f0f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from PIL import Image # Can be used but cv2 is primary for this version\n",
    "import cv2 # OpenCV for image reading/processing\n",
    "\n",
    "# TensorFlow & Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping # Added EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam # Changed from optimizers import *\n",
    "# Removed Keras ImageDataGenerator - replaced by custom Sequence\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "# Import the specific preprocessing function for DenseNet\n",
    "from tensorflow.keras.applications.densenet import preprocess_input as densenet_preprocess_input\n",
    "# Removed Activation, MaxNorm, model_from_json, l2, Conv2D, MaxPooling2D, VGG16 if not used\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder # Added for label handling\n",
    "\n",
    "# Albumentations\n",
    "import albumentations as A # Added for augmentation\n",
    "\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "print(\"Albumentations Version:\", A.__version__) # Added\n",
    "print(\"OpenCV Version:\", cv2.__version__)       # Added"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfaa22e",
   "metadata": {},
   "source": [
    "### II. Read Dataset and Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5571a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the Directory Containing the Images\n",
    "dataset_dir = '../Dataset_BUSI_with_GT'\n",
    "\n",
    "# Model Saving Configuration (New)\n",
    "model_save_dir = './model_minimal_augment'\n",
    "weights_path = '../model/weights/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5' # Path to pre-trained weights if needed locally\n",
    "best_model_path = './model_minimal_augment/best_model.keras' # Path to the best model\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "# --- NEW: Robust Data Collection (Replaces old glob method and Section IV) ---\n",
    "if not os.path.isdir(dataset_dir):\n",
    "    raise ValueError(f\"Dataset directory not found at: {dataset_dir}\")\n",
    "\n",
    "data_paths = []\n",
    "labels = []\n",
    "class_names = sorted([d for d in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, d))])\n",
    "print(f\"Found classes: {class_names}\")\n",
    "\n",
    "for folder_name in class_names:\n",
    "    folder_path = os.path.join(dataset_dir, folder_name)\n",
    "    files = glob.glob(os.path.join(folder_path, '*.*'))\n",
    "    image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]\n",
    "\n",
    "    original_images = []\n",
    "    skipped_masks = 0\n",
    "    skipped_invalid = 0 # Added check\n",
    "    for f in image_files:\n",
    "        base_name = os.path.basename(f).lower()\n",
    "        # Filter out masks\n",
    "        if '_mask' in base_name:\n",
    "            skipped_masks += 1\n",
    "            continue\n",
    "        # Optional: Basic check for image validity\n",
    "        try:\n",
    "             img_check = cv2.imread(f)\n",
    "             if img_check is None or len(img_check.shape) < 2 or img_check.shape[0] < 10 or img_check.shape[1] < 10:\n",
    "                 print(f\"Warning: Image seems invalid or unreadable, skipping: {f}\")\n",
    "                 skipped_invalid +=1\n",
    "                 continue\n",
    "        except Exception as e:\n",
    "             print(f\"Warning: Error reading image {f}, skipping. Error: {e}\")\n",
    "             skipped_invalid += 1\n",
    "             continue\n",
    "        original_images.append(f)\n",
    "\n",
    "    print(f\"Class '{folder_name}': Found {len(original_images)} original images (skipped {skipped_masks} masks, {skipped_invalid} invalid).\")\n",
    "\n",
    "    for file_path in original_images:\n",
    "        data_paths.append(file_path)\n",
    "        labels.append(folder_name)\n",
    "\n",
    "# Create DataFrame from collected paths and labels\n",
    "all_data_df = pd.DataFrame({'Path': data_paths, 'Label': labels})\n",
    "\n",
    "print(f\"\\nTotal original images loaded: {len(all_data_df)}\")\n",
    "if len(all_data_df) == 0:\n",
    "    raise ValueError(\"No valid images found after filtering. Check dataset path and mask naming.\")\n",
    "\n",
    "# Display Sample Data\n",
    "print(\"Sample data:\")\n",
    "print(all_data_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31a93e6",
   "metadata": {},
   "source": [
    "### III. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022508a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Overall Class Distribution (Using the filtered DataFrame)\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.countplot(x='Label', data=all_data_df, order=class_names) # Use filtered df\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='center', xytext=(0, 5), textcoords='offset points', fontsize=8)\n",
    "plt.xticks(rotation=30)\n",
    "plt.title(f'Original Image Distribution (Total: {len(all_data_df)})', pad=10) # Updated title\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88e7216",
   "metadata": {},
   "source": [
    "### IV. Data Preprocessing & Data Generation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6301b580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "batch_size = 16\n",
    "image_height = 256\n",
    "image_width = 256\n",
    "num_channels = 3 # DenseNet expects 3 channels\n",
    "image_size = (image_height, image_width)\n",
    "image_shape = (image_height, image_width, num_channels)\n",
    "num_classes = len(class_names) # Get num_classes dynamically\n",
    "\n",
    "# --- Label Encoding ---\n",
    "label_encoder = LabelEncoder()\n",
    "all_data_df['Label_Encoded'] = label_encoder.fit_transform(all_data_df['Label'])\n",
    "class_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(f\"\\nClass mapping: {class_mapping}\")\n",
    "\n",
    "# --- Data Splitting (with Stratification) ---\n",
    "# Using random_state=123 for consistency if needed, added stratification\n",
    "train_df, val_test_df = train_test_split(\n",
    "    all_data_df,\n",
    "    train_size=0.8,\n",
    "    shuffle=True,\n",
    "    random_state=123,\n",
    "    stratify=all_data_df['Label_Encoded'] # Added stratification\n",
    ")\n",
    "val_df, test_df = train_test_split(\n",
    "    val_test_df,\n",
    "    train_size=0.5,\n",
    "    shuffle=True,\n",
    "    random_state=123,\n",
    "    stratify=val_test_df['Label_Encoded'] # Added stratification\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset Split:\")\n",
    "print(f\"Train samples: {len(train_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "# Optional: print class distribution per set\n",
    "# print(\"\\nTrain Data Distribution:\"); print(train_df['Label'].value_counts())\n",
    "# print(\"\\nValidation Data Distribution:\"); print(val_df['Label'].value_counts())\n",
    "# print(\"\\nTest Data Distribution:\"); print(test_df['Label'].value_counts())\n",
    "\n",
    "# --- Albumentations Augmentation Definitions ---\n",
    "print(\"\\nDefining Albumentations transforms...\")\n",
    "# Using MINIMAL augmentations based on previous results\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(height=image_height, width=image_width, interpolation=cv2.INTER_LINEAR),\n",
    "    A.HorizontalFlip(p=0.5), # Only random augmentation\n",
    "])\n",
    "val_test_transform = A.Compose([\n",
    "    A.Resize(height=image_height, width=image_width, interpolation=cv2.INTER_LINEAR) # Resize only for val/test\n",
    "])\n",
    "print(\"Using MINIMAL augmentations: Resize + HorizontalFlip only for training.\")\n",
    "\n",
    "# --- Custom Keras Data Generator (Replaces ImageDataGenerator) ---\n",
    "print(\"Defining custom DataGenerator Sequence...\")\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, df, batch_size, image_size, num_classes, augmentations=None, shuffle=True, preprocess_fn=None):\n",
    "        self.df = df.copy()\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.num_classes = num_classes\n",
    "        self.augmentations = augmentations\n",
    "        self.shuffle = shuffle\n",
    "        self.preprocess_fn = preprocess_fn # Added for DenseNet preprocessing\n",
    "        self.indices = np.arange(len(self.df))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_df = self.df.iloc[batch_indices]\n",
    "        X = np.zeros((len(batch_df), *self.image_size, num_channels), dtype=np.float32)\n",
    "        y = np.zeros((len(batch_df), self.num_classes), dtype=np.float32)\n",
    "\n",
    "        for i, (idx, row) in enumerate(batch_df.iterrows()):\n",
    "            img_path = row['Path']\n",
    "            label_encoded = row['Label_Encoded']\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                # Handle error: print warning and use zeros\n",
    "                print(f\"Warning: Could not read image {img_path} in generator. Filling with zeros.\")\n",
    "                img = np.zeros((*self.image_size, num_channels), dtype=np.uint8)\n",
    "            else:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            if self.augmentations: # Apply Albumentations\n",
    "                augmented = self.augmentations(image=img)\n",
    "                img = augmented['image']\n",
    "\n",
    "            # Ensure correct size after augmentation (fallback)\n",
    "            if img.shape[0] != self.image_size[0] or img.shape[1] != self.image_size[1]:\n",
    "                 img = cv2.resize(img, (self.image_size[1], self.image_size[0]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "            img = img.astype(np.float32)\n",
    "            # Apply specific DenseNet preprocessing function\n",
    "            if self.preprocess_fn:\n",
    "                img = self.preprocess_fn(img)\n",
    "            else: # Fallback (should not be used with DenseNet)\n",
    "                 img = img / 255.0\n",
    "\n",
    "            X[i,] = img\n",
    "            y[i,] = to_categorical(label_encoded, num_classes=self.num_classes) # One-hot encode\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "# --- Instantiate Data Generators ---\n",
    "print(\"\\nCreating Data Generators...\")\n",
    "train_generator = DataGenerator(\n",
    "    train_df, batch_size, image_size, num_classes,\n",
    "    augmentations=train_transform, shuffle=True,\n",
    "    preprocess_fn=densenet_preprocess_input # Use DenseNet preprocessing\n",
    ")\n",
    "valid_generator = DataGenerator(\n",
    "    val_df, batch_size, image_size, num_classes,\n",
    "    augmentations=val_test_transform, shuffle=False, # No shuffle/augmentation for validation\n",
    "    preprocess_fn=densenet_preprocess_input\n",
    ")\n",
    "test_generator = DataGenerator( # Added test generator definition here\n",
    "    test_df, batch_size, image_size, num_classes,\n",
    "    augmentations=val_test_transform, shuffle=False, # No shuffle/augmentation for test\n",
    "    preprocess_fn=densenet_preprocess_input\n",
    ")\n",
    "\n",
    "print(f\"Train generator: {len(train_generator)} batches\")\n",
    "print(f\"Validation generator: {len(valid_generator)} batches\")\n",
    "print(f\"Test generator: {len(test_generator)} batches\")\n",
    "\n",
    "# --- Visualize Augmented Images (Corrected Method) ---\n",
    "print(\"\\nVisualizing sample augmented training images (BEFORE DenseNet preprocessing)...\")\n",
    "\n",
    "# Get the first batch's indices from the generator to find corresponding df rows\n",
    "batch_indices = train_generator.indices[0 * train_generator.batch_size:(0 + 1) * train_generator.batch_size]\n",
    "batch_df_sample = train_generator.df.iloc[batch_indices]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "num_images_to_show = min(len(batch_df_sample), 8) # Show up to 8 images or batch size\n",
    "\n",
    "for i in range(num_images_to_show):\n",
    "    try:\n",
    "        # Get the image path and label from the dataframe for this index\n",
    "        img_path = batch_df_sample.iloc[i]['Path']\n",
    "        label_encoded = batch_df_sample.iloc[i]['Label_Encoded']\n",
    "        label_name = label_encoder.inverse_transform([label_encoded])[0]\n",
    "\n",
    "        # --- Re-load the original image ---\n",
    "        img_original = cv2.imread(img_path)\n",
    "        if img_original is None:\n",
    "            print(f\"Warning: Could not reload image {img_path} for visualization.\")\n",
    "            continue\n",
    "        img_rgb = cv2.cvtColor(img_original, cv2.COLOR_BGR2RGB) # Convert to RGB\n",
    "\n",
    "        # --- Apply ONLY the Albumentations transform ---\n",
    "        # This shows the output of train_transform before DenseNet preprocessing\n",
    "        augmented_data = train_transform(image=img_rgb)\n",
    "        img_augmented_display = augmented_data['image'] # This is uint8 [0, 255]\n",
    "\n",
    "        # --- Display the result of Albumentations ---\n",
    "        plt.subplot(2, 4, i + 1)\n",
    "        plt.imshow(img_augmented_display) # Display the correctly augmented image\n",
    "        plt.title(f\"Label: {label_name}\\n(Augmented)\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error visualizing image index {i}: {e}\")\n",
    "        # Optionally display a blank subplot or skip\n",
    "        plt.subplot(2, 4, i + 1)\n",
    "        plt.title(\"Error Loading\")\n",
    "        plt.axis('off')\n",
    "\n",
    "\n",
    "plt.suptitle(\"Sample Augmented Training Images (Result of Albumentations)\")\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to prevent title overlap\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- Display Class Indices (as in old notebook) ---\n",
    "# Get class indices from the generator (useful for mapping predictions)\n",
    "# class_indices = train_generator.class_indices # Custom generator doesn't have this attribute directly\n",
    "# Use the mapping created earlier\n",
    "print(\"\\nClass Indices Mapping Used:\")\n",
    "print(class_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc9cb0f",
   "metadata": {},
   "source": [
    "### V. BUILD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4655dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VI. Build Model\n",
    "print(\"\\nBuilding Model...\")\n",
    "\n",
    "# Check if weights file exists if loading locally\n",
    "# if not os.path.isfile(weights_path):\n",
    "#      raise ValueError(f\"DenseNet weights file not found at: {weights_path}\")\n",
    "\n",
    "# Load the DenseNet-121 base model\n",
    "base_model = DenseNet121(\n",
    "    # weights=weights_path, # Use local weights if needed\n",
    "    weights='imagenet',    # Or load directly from Keras repository\n",
    "    include_top=False,     # Exclude the final Dense layers\n",
    "    input_shape=image_shape # Use defined image shape\n",
    ")\n",
    "\n",
    "# Freeze base model layers\n",
    "base_model.trainable = False\n",
    "print(\"DenseNet121 base model loaded and frozen.\")\n",
    "\n",
    "# Create the Sequential model with custom head\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(1024, activation='relu', name='dense_1024_1'),\n",
    "    Dropout(0.4, name='dropout_1'), # Added dropout\n",
    "    Dense(512, activation='relu', name='dense_512'),\n",
    "    Dropout(0.2, name='dropout_2'), # Added dropout\n",
    "    Dense(128, activation='relu', name='dense_128'),\n",
    "    Dense(num_classes, activation='softmax', name='output') # Output layer size matches num_classes\n",
    "], name='Breast_Tumor_Classifier_Minimal_Augment') # Model name updated\n",
    "\n",
    "# Display model summary\n",
    "model.summary()\n",
    "\n",
    "# --- Define Callbacks ---\n",
    "print(\"\\nDefining Callbacks...\")\n",
    "# Model Checkpoint Callback\n",
    "checkpoint = ModelCheckpoint(\n",
    "    best_model_path,            # Path to save the best model\n",
    "    monitor='val_accuracy',     # Monitor validation accuracy\n",
    "    save_best_only=True,        # Save only the best\n",
    "    mode='max',                 # Maximize monitored metric\n",
    "    verbose=1                   # Print messages\n",
    ")\n",
    "print(f\"Model checkpoints will be saved to {best_model_path}\")\n",
    "\n",
    "# Early Stopping Callback (New)\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=10,            # Stop after 10 epochs of no improvement\n",
    "    verbose=1,\n",
    "    mode='max',\n",
    "    restore_best_weights=True # Restore weights from the best epoch\n",
    ")\n",
    "print(\"Early stopping configured (patience=10 on val_accuracy).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549966b6",
   "metadata": {},
   "source": [
    "### VI. Compile Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423b5631",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCompiling Model...\")\n",
    "# Using Adam optimizer with a potentially lower learning rate\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "print(\"Model Compiled Successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad6460d",
   "metadata": {},
   "source": [
    "### VII. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef02a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- THIS SECTION IS COMMENTED OUT AS THE PROVIDED CODE LOADS A PRE-TRAINED MODEL ---\n",
    "# print(\"\\nStarting Training...\")\n",
    "# epochs = 50 # Define number of epochs\n",
    "\n",
    "# history = model.fit(\n",
    "#     train_generator,\n",
    "#     epochs=epochs,\n",
    "#     validation_data=valid_generator,\n",
    "#     callbacks=[checkpoint, early_stopping], # Use both callbacks\n",
    "#     # steps_per_epoch and validation_steps inferred from generator length\n",
    "#     verbose=1\n",
    "# )\n",
    "# print(\"Training Finished.\")\n",
    "# --- END OF COMMENTED OUT TRAINING SECTION ---\n",
    "best_model_path = '../model_minimal_augment/best_model.keras' # Path to the best model\n",
    "# --- Load Best Model (as per provided new code) ---\n",
    "print(f\"\\n--- Loading Pre-Trained Best Model ---\")\n",
    "print(f\"Attempting to load model from: {best_model_path}\")\n",
    "try:\n",
    "    # Load the best model explicitly saved by the checkpoint callback during a previous run\n",
    "    model = load_model(best_model_path)\n",
    "    print(\"Best model loaded successfully for evaluation.\")\n",
    "    # Verify the model architecture after loading (optional)\n",
    "    # model.summary()\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Could not load the model from {best_model_path}.\")\n",
    "    print(f\"Ensure the model was trained and saved correctly in a previous run.\")\n",
    "    print(f\"Error details: {e}\")\n",
    "    # Depending on workflow, you might want to raise an error or exit here\n",
    "    # raise RuntimeError(\"Failed to load the required model for evaluation.\") from e\n",
    "    model = None # Set model to None if loading failed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a63bfd",
   "metadata": {},
   "source": [
    "### VIII. Evaluate Model (Train & Validation Set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745a1d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model is not None: # Only proceed if model loaded successfully\n",
    "    print(\"\\nEvaluating best model on Training and Validation Sets...\")\n",
    "    # Note: Evaluating on train_generator after loading might reflect last state,\n",
    "    # but standard practice evaluates the *best* checkpoint.\n",
    "    train_loss, train_accuracy = model.evaluate(train_generator, verbose=0)\n",
    "    val_loss, val_accuracy = model.evaluate(valid_generator, verbose=0)\n",
    "\n",
    "    train_accuracy_percentage = train_accuracy * 100\n",
    "    val_accuracy_percentage = val_accuracy * 100\n",
    "    evaluation_results = pd.DataFrame({\n",
    "        'Set': ['Train', 'Validation'],\n",
    "        'Loss': [train_loss, val_loss],\n",
    "        'Accuracy': [f'{train_accuracy_percentage:.2f}%', f'{val_accuracy_percentage:.2f}%']\n",
    "    })\n",
    "    print(\"\\nLoaded Model Evaluation (Train/Validation):\")\n",
    "    print(evaluation_results)\n",
    "\n",
    "    # Plot Loss & Accuracy Curves\n",
    "    # --- THIS SECTION WILL CAUSE AN ERROR IF TRAINING WASN'T RUN IN THIS SESSION ---\n",
    "    # Because the 'history' object is not available when loading a saved model directly.\n",
    "    print(\"\\nPlotting Training History... (Requires 'history' object from training)\")\n",
    "    # Wrap in try-except or only run if model.fit was executed in the same session\n",
    "    try:\n",
    "        # This part assumes 'history' variable exists from model.fit()\n",
    "        train_history_df = pd.DataFrame(history.history)\n",
    "        final_epoch = len(train_history_df)\n",
    "        train_history_df['Epoch'] = range(1, final_epoch + 1)\n",
    "\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(train_history_df['Epoch'], train_history_df['loss'], label='Training Loss')\n",
    "        plt.plot(train_history_df['Epoch'], train_history_df['val_loss'], label='Validation Loss')\n",
    "        plt.title('Training & Validation Loss')\n",
    "        plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend(); plt.grid(True)\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(train_history_df['Epoch'], train_history_df['accuracy'], label='Training Accuracy')\n",
    "        plt.plot(train_history_df['Epoch'], train_history_df['val_accuracy'], label='Validation Accuracy')\n",
    "        plt.title('Training & Validation Accuracy')\n",
    "        plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.legend(); plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plot_save_path = os.path.join(model_save_dir, 'training_history_plot.png')\n",
    "        plt.savefig(plot_save_path)\n",
    "        print(f\"Training history plot saved to {plot_save_path}\")\n",
    "        plt.show()\n",
    "    except NameError:\n",
    "        print(\"Variable 'history' not defined. Cannot plot training history.\")\n",
    "        print(\"Run model.fit() in the current session to generate history.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while plotting history: {e}\")\n",
    "    # --- END OF PLOTTING SECTION ---\n",
    "\n",
    "else:\n",
    "    print(\"\\nSkipping Evaluation and Plotting as model loading failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcef6ed",
   "metadata": {},
   "source": [
    "### IX. Test Model (Evaluate on Test Set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220ee9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Old notebook used X for download, this section now evaluates on the test set)\n",
    "if model is not None: # Only proceed if model loaded successfully\n",
    "    print(\"\\n--- Evaluating the best model on the Test Set ---\")\n",
    "    test_loss, test_accuracy = model.evaluate(test_generator, verbose=1)\n",
    "    print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "else:\n",
    "     print(\"\\nSkipping Test Set Evaluation as model loading failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbc1756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XI. Test Model (Single Image Prediction)\n",
    "if model is not None: # Only proceed if model loaded successfully\n",
    "    print(\"\\n--- Running prediction on a sample test image ---\")\n",
    "    if not test_df.empty:\n",
    "        # Select a random sample from the test set\n",
    "        sample_row = test_df.sample(1).iloc[0]\n",
    "        test_image_path = sample_row['Path']\n",
    "        true_label = sample_row['Label']\n",
    "        print(f\"Using test image: {test_image_path}\")\n",
    "        print(f\"True label: {true_label}\")\n",
    "\n",
    "        # Define the preprocessing function for a single image prediction\n",
    "        def preprocess_single_image_for_predict(image_path, target_size, preprocess_fn):\n",
    "            img = cv2.imread(image_path)\n",
    "            if img is None:\n",
    "                raise ValueError(f\"Could not read image: {image_path}\")\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            # Resize using OpenCV\n",
    "            img = cv2.resize(img, (target_size[1], target_size[0]), interpolation=cv2.INTER_LINEAR)\n",
    "            # Convert to float32 and apply DenseNet preprocessing\n",
    "            img_array = img.astype(np.float32)\n",
    "            img_array = preprocess_fn(img_array)\n",
    "            # Add batch dimension\n",
    "            img_array = np.expand_dims(img_array, axis=0)\n",
    "            return img_array\n",
    "\n",
    "        try:\n",
    "            # Preprocess the sample image\n",
    "            preprocessed_image = preprocess_single_image_for_predict(\n",
    "                test_image_path,\n",
    "                image_size, # Use configured image size\n",
    "                densenet_preprocess_input # Use the correct preprocessing function\n",
    "            )\n",
    "\n",
    "            # Make prediction\n",
    "            predictions = model.predict(preprocessed_image)\n",
    "            predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
    "            # Use the label_encoder fitted earlier to map index back to label\n",
    "            predicted_class_label = label_encoder.inverse_transform([predicted_class_index])[0]\n",
    "            confidence = predictions[0][predicted_class_index]\n",
    "\n",
    "            print(f\"\\nPredicted Class: {predicted_class_label}\")\n",
    "            print(f\"Prediction Confidence: {confidence:.4f}\")\n",
    "\n",
    "            # Display confidence scores for all classes\n",
    "            print(\"Confidence Scores:\")\n",
    "            # Use label_encoder.classes_ for correct order\n",
    "            for i, class_name in enumerate(label_encoder.classes_):\n",
    "                 print(f\"  - {class_name}: {predictions[0][i]:.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during single image prediction: {e}\")\n",
    "    else:\n",
    "        print(\"Test set DataFrame (test_df) is empty, cannot select a sample image.\")\n",
    "else:\n",
    "     print(\"\\nSkipping Single Image Prediction as model loading failed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tumor_classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
