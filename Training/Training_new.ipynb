{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da5bca5f",
   "metadata": {},
   "source": [
    "### I. Import Required Dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "195f0f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 16:25:30.384884: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-01 16:25:30.431121: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/chaoder/miniconda3/envs/tumor_classification/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2025-05-01 16:25:30.431170: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.9.0\n",
      "Albumentations Version: 1.4.18\n",
      "OpenCV Version: 4.11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chaoder/miniconda3/envs/tumor_classification/lib/python3.8/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.6 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from PIL import Image # Can be used but cv2 is primary for this version\n",
    "import cv2 # OpenCV for image reading/processing\n",
    "\n",
    "# TensorFlow & Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping # Added EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam # Changed from optimizers import *\n",
    "# Removed Keras ImageDataGenerator - replaced by custom Sequence\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "# Import the specific preprocessing function for DenseNet\n",
    "from tensorflow.keras.applications.densenet import preprocess_input as densenet_preprocess_input\n",
    "# Removed Activation, MaxNorm, model_from_json, l2, Conv2D, MaxPooling2D, VGG16 if not used\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder # Added for label handling\n",
    "\n",
    "# Albumentations\n",
    "import albumentations as A # Added for augmentation\n",
    "\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "print(\"Albumentations Version:\", A.__version__) # Added\n",
    "print(\"OpenCV Version:\", cv2.__version__)       # Added"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfaa22e",
   "metadata": {},
   "source": [
    "### II. Read Dataset and Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5571a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_save_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m weights_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../model/weights/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# Path to pre-trained weights if needed locally\u001b[39;00m\n\u001b[1;32m      7\u001b[0m best_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./model_minimal_augment/best_model.keras\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# Path to the best model\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[43mmodel_save_dir\u001b[49m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# --- NEW: Robust Data Collection (Replaces old glob method and Section IV) ---\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dataset_dir):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_save_dir' is not defined"
     ]
    }
   ],
   "source": [
    "# Path to the Directory Containing the Images\n",
    "dataset_dir = '../Dataset_BUSI_with_GT'\n",
    "\n",
    "# Model Saving Configuration (New)\n",
    "model_save_dir = './model_minimal_augment'\n",
    "weights_path = '../model/weights/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5' # Path to pre-trained weights if needed locally\n",
    "best_model_path = './model_minimal_augment/best_model.keras' # Path to the best model\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "# --- NEW: Robust Data Collection (Replaces old glob method and Section IV) ---\n",
    "if not os.path.isdir(dataset_dir):\n",
    "    raise ValueError(f\"Dataset directory not found at: {dataset_dir}\")\n",
    "\n",
    "data_paths = []\n",
    "labels = []\n",
    "class_names = sorted([d for d in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, d))])\n",
    "print(f\"Found classes: {class_names}\")\n",
    "\n",
    "for folder_name in class_names:\n",
    "    folder_path = os.path.join(dataset_dir, folder_name)\n",
    "    files = glob.glob(os.path.join(folder_path, '*.*'))\n",
    "    image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]\n",
    "\n",
    "    original_images = []\n",
    "    skipped_masks = 0\n",
    "    skipped_invalid = 0 # Added check\n",
    "    for f in image_files:\n",
    "        base_name = os.path.basename(f).lower()\n",
    "        # Filter out masks\n",
    "        if '_mask' in base_name:\n",
    "            skipped_masks += 1\n",
    "            continue\n",
    "        # Optional: Basic check for image validity\n",
    "        try:\n",
    "             img_check = cv2.imread(f)\n",
    "             if img_check is None or len(img_check.shape) < 2 or img_check.shape[0] < 10 or img_check.shape[1] < 10:\n",
    "                 print(f\"Warning: Image seems invalid or unreadable, skipping: {f}\")\n",
    "                 skipped_invalid +=1\n",
    "                 continue\n",
    "        except Exception as e:\n",
    "             print(f\"Warning: Error reading image {f}, skipping. Error: {e}\")\n",
    "             skipped_invalid += 1\n",
    "             continue\n",
    "        original_images.append(f)\n",
    "\n",
    "    print(f\"Class '{folder_name}': Found {len(original_images)} original images (skipped {skipped_masks} masks, {skipped_invalid} invalid).\")\n",
    "\n",
    "    for file_path in original_images:\n",
    "        data_paths.append(file_path)\n",
    "        labels.append(folder_name)\n",
    "\n",
    "# Create DataFrame from collected paths and labels\n",
    "all_data_df = pd.DataFrame({'Path': data_paths, 'Label': labels})\n",
    "\n",
    "print(f\"\\nTotal original images loaded: {len(all_data_df)}\")\n",
    "if len(all_data_df) == 0:\n",
    "    raise ValueError(\"No valid images found after filtering. Check dataset path and mask naming.\")\n",
    "\n",
    "# Display Sample Data\n",
    "print(\"Sample data:\")\n",
    "print(all_data_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31a93e6",
   "metadata": {},
   "source": [
    "### III. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "022508a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display Overall Class Distribution (Using the filtered DataFrame)\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.countplot(x='Label', data=all_data_df, order=class_names) # Use filtered df\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='center', xytext=(0, 5), textcoords='offset points', fontsize=8)\n",
    "plt.xticks(rotation=30)\n",
    "plt.title(f'Original Image Distribution (Total: {len(all_data_df)})', pad=10) # Updated title\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88e7216",
   "metadata": {},
   "source": [
    "### IV. Data Preprocessing & Data Generation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6301b580",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'class_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m image_size \u001b[38;5;241m=\u001b[39m (image_height, image_width)\n\u001b[1;32m      7\u001b[0m image_shape \u001b[38;5;241m=\u001b[39m (image_height, image_width, num_channels)\n\u001b[0;32m----> 8\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mclass_names\u001b[49m) \u001b[38;5;66;03m# Get num_classes dynamically\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# --- Label Encoding ---\u001b[39;00m\n\u001b[1;32m     11\u001b[0m label_encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'class_names' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "batch_size = 16\n",
    "image_height = 256\n",
    "image_width = 256\n",
    "num_channels = 3 # DenseNet expects 3 channels\n",
    "image_size = (image_height, image_width)\n",
    "image_shape = (image_height, image_width, num_channels)\n",
    "num_classes = len(class_names) # Get num_classes dynamically\n",
    "\n",
    "# --- Label Encoding ---\n",
    "label_encoder = LabelEncoder()\n",
    "all_data_df['Label_Encoded'] = label_encoder.fit_transform(all_data_df['Label'])\n",
    "class_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(f\"\\nClass mapping: {class_mapping}\")\n",
    "\n",
    "# --- Data Splitting (with Stratification) ---\n",
    "# Using random_state=123 for consistency if needed, added stratification\n",
    "train_df, val_test_df = train_test_split(\n",
    "    all_data_df,\n",
    "    train_size=0.8,\n",
    "    shuffle=True,\n",
    "    random_state=123,\n",
    "    stratify=all_data_df['Label_Encoded'] # Added stratification\n",
    ")\n",
    "val_df, test_df = train_test_split(\n",
    "    val_test_df,\n",
    "    train_size=0.5,\n",
    "    shuffle=True,\n",
    "    random_state=123,\n",
    "    stratify=val_test_df['Label_Encoded'] # Added stratification\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset Split:\")\n",
    "print(f\"Train samples: {len(train_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "# Optional: print class distribution per set\n",
    "# print(\"\\nTrain Data Distribution:\"); print(train_df['Label'].value_counts())\n",
    "# print(\"\\nValidation Data Distribution:\"); print(val_df['Label'].value_counts())\n",
    "# print(\"\\nTest Data Distribution:\"); print(test_df['Label'].value_counts())\n",
    "\n",
    "# --- Albumentations Augmentation Definitions ---\n",
    "print(\"\\nDefining Albumentations transforms...\")\n",
    "# Using MINIMAL augmentations based on previous results\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(height=image_height, width=image_width, interpolation=cv2.INTER_LINEAR),\n",
    "    A.HorizontalFlip(p=0.5), # Only random augmentation\n",
    "])\n",
    "val_test_transform = A.Compose([\n",
    "    A.Resize(height=image_height, width=image_width, interpolation=cv2.INTER_LINEAR) # Resize only for val/test\n",
    "])\n",
    "print(\"Using MINIMAL augmentations: Resize + HorizontalFlip only for training.\")\n",
    "\n",
    "# --- Custom Keras Data Generator (Replaces ImageDataGenerator) ---\n",
    "print(\"Defining custom DataGenerator Sequence...\")\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, df, batch_size, image_size, num_classes, augmentations=None, shuffle=True, preprocess_fn=None):\n",
    "        self.df = df.copy()\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.num_classes = num_classes\n",
    "        self.augmentations = augmentations\n",
    "        self.shuffle = shuffle\n",
    "        self.preprocess_fn = preprocess_fn # Added for DenseNet preprocessing\n",
    "        self.indices = np.arange(len(self.df))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_df = self.df.iloc[batch_indices]\n",
    "        X = np.zeros((len(batch_df), *self.image_size, num_channels), dtype=np.float32)\n",
    "        y = np.zeros((len(batch_df), self.num_classes), dtype=np.float32)\n",
    "\n",
    "        for i, (idx, row) in enumerate(batch_df.iterrows()):\n",
    "            img_path = row['Path']\n",
    "            label_encoded = row['Label_Encoded']\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                # Handle error: print warning and use zeros\n",
    "                print(f\"Warning: Could not read image {img_path} in generator. Filling with zeros.\")\n",
    "                img = np.zeros((*self.image_size, num_channels), dtype=np.uint8)\n",
    "            else:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            if self.augmentations: # Apply Albumentations\n",
    "                augmented = self.augmentations(image=img)\n",
    "                img = augmented['image']\n",
    "\n",
    "            # Ensure correct size after augmentation (fallback)\n",
    "            if img.shape[0] != self.image_size[0] or img.shape[1] != self.image_size[1]:\n",
    "                 img = cv2.resize(img, (self.image_size[1], self.image_size[0]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "            img = img.astype(np.float32)\n",
    "            # Apply specific DenseNet preprocessing function\n",
    "            if self.preprocess_fn:\n",
    "                img = self.preprocess_fn(img)\n",
    "            else: # Fallback (should not be used with DenseNet)\n",
    "                 img = img / 255.0\n",
    "\n",
    "            X[i,] = img\n",
    "            y[i,] = to_categorical(label_encoded, num_classes=self.num_classes) # One-hot encode\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "# --- Instantiate Data Generators ---\n",
    "print(\"\\nCreating Data Generators...\")\n",
    "train_generator = DataGenerator(\n",
    "    train_df, batch_size, image_size, num_classes,\n",
    "    augmentations=train_transform, shuffle=True,\n",
    "    preprocess_fn=densenet_preprocess_input # Use DenseNet preprocessing\n",
    ")\n",
    "valid_generator = DataGenerator(\n",
    "    val_df, batch_size, image_size, num_classes,\n",
    "    augmentations=val_test_transform, shuffle=False, # No shuffle/augmentation for validation\n",
    "    preprocess_fn=densenet_preprocess_input\n",
    ")\n",
    "test_generator = DataGenerator( # Added test generator definition here\n",
    "    test_df, batch_size, image_size, num_classes,\n",
    "    augmentations=val_test_transform, shuffle=False, # No shuffle/augmentation for test\n",
    "    preprocess_fn=densenet_preprocess_input\n",
    ")\n",
    "\n",
    "print(f\"Train generator: {len(train_generator)} batches\")\n",
    "print(f\"Validation generator: {len(valid_generator)} batches\")\n",
    "print(f\"Test generator: {len(test_generator)} batches\")\n",
    "\n",
    "# --- Visualize Augmented Images (Corrected Method) ---\n",
    "print(\"\\nVisualizing sample augmented training images (BEFORE DenseNet preprocessing)...\")\n",
    "\n",
    "# Get the first batch's indices from the generator to find corresponding df rows\n",
    "batch_indices = train_generator.indices[0 * train_generator.batch_size:(0 + 1) * train_generator.batch_size]\n",
    "batch_df_sample = train_generator.df.iloc[batch_indices]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "num_images_to_show = min(len(batch_df_sample), 8) # Show up to 8 images or batch size\n",
    "\n",
    "for i in range(num_images_to_show):\n",
    "    try:\n",
    "        # Get the image path and label from the dataframe for this index\n",
    "        img_path = batch_df_sample.iloc[i]['Path']\n",
    "        label_encoded = batch_df_sample.iloc[i]['Label_Encoded']\n",
    "        label_name = label_encoder.inverse_transform([label_encoded])[0]\n",
    "\n",
    "        # --- Re-load the original image ---\n",
    "        img_original = cv2.imread(img_path)\n",
    "        if img_original is None:\n",
    "            print(f\"Warning: Could not reload image {img_path} for visualization.\")\n",
    "            continue\n",
    "        img_rgb = cv2.cvtColor(img_original, cv2.COLOR_BGR2RGB) # Convert to RGB\n",
    "\n",
    "        # --- Apply ONLY the Albumentations transform ---\n",
    "        # This shows the output of train_transform before DenseNet preprocessing\n",
    "        augmented_data = train_transform(image=img_rgb)\n",
    "        img_augmented_display = augmented_data['image'] # This is uint8 [0, 255]\n",
    "\n",
    "        # --- Display the result of Albumentations ---\n",
    "        plt.subplot(2, 4, i + 1)\n",
    "        plt.imshow(img_augmented_display) # Display the correctly augmented image\n",
    "        plt.title(f\"Label: {label_name}\\n(Augmented)\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error visualizing image index {i}: {e}\")\n",
    "        # Optionally display a blank subplot or skip\n",
    "        plt.subplot(2, 4, i + 1)\n",
    "        plt.title(\"Error Loading\")\n",
    "        plt.axis('off')\n",
    "\n",
    "\n",
    "plt.suptitle(\"Sample Augmented Training Images (Result of Albumentations)\")\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to prevent title overlap\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- Display Class Indices (as in old notebook) ---\n",
    "# Get class indices from the generator (useful for mapping predictions)\n",
    "# class_indices = train_generator.class_indices # Custom generator doesn't have this attribute directly\n",
    "# Use the mapping created earlier\n",
    "print(\"\\nClass Indices Mapping Used:\")\n",
    "print(class_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc9cb0f",
   "metadata": {},
   "source": [
    "### V. BUILD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac4655dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 16:17:52.428376: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-01 16:17:52.428732: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/chaoder/miniconda3/envs/tumor_classification/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2025-05-01 16:17:52.428832: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/chaoder/miniconda3/envs/tumor_classification/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2025-05-01 16:17:52.428872: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/chaoder/miniconda3/envs/tumor_classification/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2025-05-01 16:17:52.428905: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/chaoder/miniconda3/envs/tumor_classification/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2025-05-01 16:17:52.428939: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/chaoder/miniconda3/envs/tumor_classification/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2025-05-01 16:17:52.428971: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/chaoder/miniconda3/envs/tumor_classification/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2025-05-01 16:17:52.429002: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/chaoder/miniconda3/envs/tumor_classification/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2025-05-01 16:17:52.429052: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/chaoder/miniconda3/envs/tumor_classification/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2025-05-01 16:17:52.429086: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2025-05-01 16:17:52.429600: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet121 base model loaded and frozen.\n",
      "Model: \"Breast_Tumor_Classifier_Minimal_Augment\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet121 (Functional)    (None, 8, 8, 1024)        7037504   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 65536)             0         \n",
      "                                                                 \n",
      " dense_1024_1 (Dense)        (None, 1024)              67109888  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_512 (Dense)           (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 128)               65664     \n",
      "                                                                 \n",
      " output (Dense)              (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 74,738,243\n",
      "Trainable params: 67,700,739\n",
      "Non-trainable params: 7,037,504\n",
      "_________________________________________________________________\n",
      "\n",
      "Defining Callbacks...\n",
      "Model checkpoints will be saved to ./model_minimal_augment/best_model.keras\n",
      "Early stopping configured (patience=10 on val_accuracy).\n"
     ]
    }
   ],
   "source": [
    "# VI. Build Model\n",
    "print(\"\\nBuilding Model...\")\n",
    "\n",
    "# Check if weights file exists if loading locally\n",
    "# if not os.path.isfile(weights_path):\n",
    "#      raise ValueError(f\"DenseNet weights file not found at: {weights_path}\")\n",
    "\n",
    "# Load the DenseNet-121 base model\n",
    "base_model = DenseNet121(\n",
    "    # weights=weights_path, # Use local weights if needed\n",
    "    weights='imagenet',    # Or load directly from Keras repository\n",
    "    include_top=False,     # Exclude the final Dense layers\n",
    "    input_shape=image_shape # Use defined image shape\n",
    ")\n",
    "\n",
    "# Freeze base model layers\n",
    "base_model.trainable = False\n",
    "print(\"DenseNet121 base model loaded and frozen.\")\n",
    "\n",
    "# Create the Sequential model with custom head\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(1024, activation='relu', name='dense_1024_1'),\n",
    "    Dropout(0.4, name='dropout_1'), # Added dropout\n",
    "    Dense(512, activation='relu', name='dense_512'),\n",
    "    Dropout(0.2, name='dropout_2'), # Added dropout\n",
    "    Dense(128, activation='relu', name='dense_128'),\n",
    "    Dense(num_classes, activation='softmax', name='output') # Output layer size matches num_classes\n",
    "], name='Breast_Tumor_Classifier_Minimal_Augment') # Model name updated\n",
    "\n",
    "# Display model summary\n",
    "model.summary()\n",
    "\n",
    "# --- Define Callbacks ---\n",
    "print(\"\\nDefining Callbacks...\")\n",
    "# Model Checkpoint Callback\n",
    "checkpoint = ModelCheckpoint(\n",
    "    best_model_path,            # Path to save the best model\n",
    "    monitor='val_accuracy',     # Monitor validation accuracy\n",
    "    save_best_only=True,        # Save only the best\n",
    "    mode='max',                 # Maximize monitored metric\n",
    "    verbose=1                   # Print messages\n",
    ")\n",
    "print(f\"Model checkpoints will be saved to {best_model_path}\")\n",
    "\n",
    "# Early Stopping Callback (New)\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=10,            # Stop after 10 epochs of no improvement\n",
    "    verbose=1,\n",
    "    mode='max',\n",
    "    restore_best_weights=True # Restore weights from the best epoch\n",
    ")\n",
    "print(\"Early stopping configured (patience=10 on val_accuracy).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549966b6",
   "metadata": {},
   "source": [
    "### VI. Compile Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423b5631",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCompiling Model...\")\n",
    "# Using Adam optimizer with a potentially lower learning rate\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "print(\"Model Compiled Successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad6460d",
   "metadata": {},
   "source": [
    "### VII. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aef02a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading Pre-Trained Best Model ---\n",
      "Attempting to load model from: ../model_minimal_augment/best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 16:28:53.225567: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-01 16:28:53.225999: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/chaoder/miniconda3/envs/tumor_classification/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2025-05-01 16:28:53.226415: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/chaoder/miniconda3/envs/tumor_classification/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2025-05-01 16:28:53.226654: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/chaoder/miniconda3/envs/tumor_classification/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2025-05-01 16:28:53.226713: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/chaoder/miniconda3/envs/tumor_classification/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2025-05-01 16:28:53.226749: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/chaoder/miniconda3/envs/tumor_classification/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2025-05-01 16:28:53.226907: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/chaoder/miniconda3/envs/tumor_classification/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2025-05-01 16:28:53.226952: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/chaoder/miniconda3/envs/tumor_classification/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2025-05-01 16:28:53.227015: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/chaoder/miniconda3/envs/tumor_classification/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2025-05-01 16:28:53.227022: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2025-05-01 16:28:53.229262: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model loaded successfully for evaluation.\n"
     ]
    }
   ],
   "source": [
    "# --- THIS SECTION IS COMMENTED OUT AS THE PROVIDED CODE LOADS A PRE-TRAINED MODEL ---\n",
    "# print(\"\\nStarting Training...\")\n",
    "# epochs = 50 # Define number of epochs\n",
    "\n",
    "# history = model.fit(\n",
    "#     train_generator,\n",
    "#     epochs=epochs,\n",
    "#     validation_data=valid_generator,\n",
    "#     callbacks=[checkpoint, early_stopping], # Use both callbacks\n",
    "#     # steps_per_epoch and validation_steps inferred from generator length\n",
    "#     verbose=1\n",
    "# )\n",
    "# print(\"Training Finished.\")\n",
    "# --- END OF COMMENTED OUT TRAINING SECTION ---\n",
    "best_model_path = '../model_minimal_augment/best_model.keras' # Path to the best model\n",
    "# --- Load Best Model (as per provided new code) ---\n",
    "print(f\"\\n--- Loading Pre-Trained Best Model ---\")\n",
    "print(f\"Attempting to load model from: {best_model_path}\")\n",
    "try:\n",
    "    # Load the best model explicitly saved by the checkpoint callback during a previous run\n",
    "    model = load_model(best_model_path)\n",
    "    print(\"Best model loaded successfully for evaluation.\")\n",
    "    # Verify the model architecture after loading (optional)\n",
    "    # model.summary()\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Could not load the model from {best_model_path}.\")\n",
    "    print(f\"Ensure the model was trained and saved correctly in a previous run.\")\n",
    "    print(f\"Error details: {e}\")\n",
    "    # Depending on workflow, you might want to raise an error or exit here\n",
    "    # raise RuntimeError(\"Failed to load the required model for evaluation.\") from e\n",
    "    model = None # Set model to None if loading failed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a63bfd",
   "metadata": {},
   "source": [
    "### VIII. Evaluate Model (Train & Validation Set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "745a1d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating best model on Training and Validation Sets...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEvaluating best model on Training and Validation Sets...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Note: Evaluating on train_generator after loading might reflect last state,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# but standard practice evaluates the *best* checkpoint.\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(\u001b[43mtrain_generator\u001b[49m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      6\u001b[0m val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(valid_generator, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      8\u001b[0m train_accuracy_percentage \u001b[38;5;241m=\u001b[39m train_accuracy \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_generator' is not defined"
     ]
    }
   ],
   "source": [
    "if model is not None: # Only proceed if model loaded successfully\n",
    "    print(\"\\nEvaluating best model on Training and Validation Sets...\")\n",
    "    # Note: Evaluating on train_generator after loading might reflect last state,\n",
    "    # but standard practice evaluates the *best* checkpoint.\n",
    "    train_loss, train_accuracy = model.evaluate(train_generator, verbose=0)\n",
    "    val_loss, val_accuracy = model.evaluate(valid_generator, verbose=0)\n",
    "\n",
    "    train_accuracy_percentage = train_accuracy * 100\n",
    "    val_accuracy_percentage = val_accuracy * 100\n",
    "    evaluation_results = pd.DataFrame({\n",
    "        'Set': ['Train', 'Validation'],\n",
    "        'Loss': [train_loss, val_loss],\n",
    "        'Accuracy': [f'{train_accuracy_percentage:.2f}%', f'{val_accuracy_percentage:.2f}%']\n",
    "    })\n",
    "    print(\"\\nLoaded Model Evaluation (Train/Validation):\")\n",
    "    print(evaluation_results)\n",
    "\n",
    "    # Plot Loss & Accuracy Curves\n",
    "    # --- THIS SECTION WILL CAUSE AN ERROR IF TRAINING WASN'T RUN IN THIS SESSION ---\n",
    "    # Because the 'history' object is not available when loading a saved model directly.\n",
    "    print(\"\\nPlotting Training History... (Requires 'history' object from training)\")\n",
    "    # Wrap in try-except or only run if model.fit was executed in the same session\n",
    "    try:\n",
    "        # This part assumes 'history' variable exists from model.fit()\n",
    "        train_history_df = pd.DataFrame(history.history)\n",
    "        final_epoch = len(train_history_df)\n",
    "        train_history_df['Epoch'] = range(1, final_epoch + 1)\n",
    "\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(train_history_df['Epoch'], train_history_df['loss'], label='Training Loss')\n",
    "        plt.plot(train_history_df['Epoch'], train_history_df['val_loss'], label='Validation Loss')\n",
    "        plt.title('Training & Validation Loss')\n",
    "        plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend(); plt.grid(True)\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(train_history_df['Epoch'], train_history_df['accuracy'], label='Training Accuracy')\n",
    "        plt.plot(train_history_df['Epoch'], train_history_df['val_accuracy'], label='Validation Accuracy')\n",
    "        plt.title('Training & Validation Accuracy')\n",
    "        plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.legend(); plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plot_save_path = os.path.join(model_save_dir, 'training_history_plot.png')\n",
    "        plt.savefig(plot_save_path)\n",
    "        print(f\"Training history plot saved to {plot_save_path}\")\n",
    "        plt.show()\n",
    "    except NameError:\n",
    "        print(\"Variable 'history' not defined. Cannot plot training history.\")\n",
    "        print(\"Run model.fit() in the current session to generate history.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while plotting history: {e}\")\n",
    "    # --- END OF PLOTTING SECTION ---\n",
    "\n",
    "else:\n",
    "    print(\"\\nSkipping Evaluation and Plotting as model loading failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcef6ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tumor_classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
